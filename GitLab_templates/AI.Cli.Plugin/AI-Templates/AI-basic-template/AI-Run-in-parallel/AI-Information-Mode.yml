# This template is used for components scanning in "Information Mode"

stages:
  - download dependencies
  - AI Scan
  - Update report status
  - Security Gates
  - Build verification
  - Notifications


# --- Pipeline Aliases ---------------------------------------

# Common docker image and GitLab Runners tags
.common-build: &common-build
  image: ${DOCKER_IMAGE}
  tags:
    - docker
    - linux
    - build-low # change to your tag

# Common structure to keep artifacts in GitLab CI Jobs
.common-artifacts: &common-artifacts
  artifacts:
    expire_in: 31 day
    paths:
      - .ai_report/

# Anchor for run condition, designed to simplify the pipeline
.on-success: &on-success
  when: on_success

# Anchor for run condition, designed to simplify the pipeline
.on-failure: &on-failure
  when: on_failure


# --- AI Aliases ----------------------------------------------------
# Common steps to start procedure for processing scan results
.codequality: &codequality >
  codequality
  -i .ai_report
  -o codequality.json
  -t ${AI_GITLAB_BOT_TOKEN}
  -s ./codequality.settings.yml | tee temp_result


# --- Additional scripts aliases ------------------------------------

# Push "Success" status with report hyperlink to parent pipeline
.push-AI-report-status-success-to-upstream: &push-AI-report-status-success-to-upstream >
  curl --location --request POST "$CI_API_V4_URL/projects/$CI_PROJECT_ID/statuses/$CI_COMMIT_SHA?state=success&name=AI%20Downstream%20Scan%20Report&description=Click%20to%20watch%20scanning%20report&target_url=$CI_JOB_URL/artifacts/browse/.ai_report/&pipeline_id=$PARENT_CI_PIPELINE_ID" --header "PRIVATE-TOKEN: ${AI_GITLAB_BOT_TOKEN}"

# Push "Security Gates: Passed / Failed" status to parent pipeline
.push-Security-Gates-status-to-upstream: &push-Security-Gates-status-to-upstream >
  if cat temp_result | grep -q "Check Security Gates: PASSED"; then
  curl --location --request POST "$CI_API_V4_URL/projects/$CI_PROJECT_ID/statuses/$CI_COMMIT_SHA?state=success&name=Code%20Quality:%20PASSED&description=Check%20Security%20Gates:%20PASSED&pipeline_id=$PARENT_CI_PIPELINE_ID"
  --header "PRIVATE-TOKEN: ${AI_GITLAB_BOT_TOKEN}";
  elif cat temp_result | grep -q "Check Security Gates: FAILED"; then
  curl --location --request POST "$CI_API_V4_URL/projects/$CI_PROJECT_ID/statuses/$CI_COMMIT_SHA?state=success&name=Code%20Quality:%20FAILED&description=Check%20Security%20Gates:%20FAILED&pipeline_id=$PARENT_CI_PIPELINE_ID"
  --header "PRIVATE-TOKEN: ${AI_GITLAB_BOT_TOKEN}"; fi && rm -rf temp_result

# --- AI Scan Stages ------------------------------------------------
# download project dependencies
include:
    - project: 'ptai-demo/pt-ai-demo-templates'
      file: '/AI-basic-template/download-dependencies.yml'

# Code scan with report generation
AI-scanning:
  <<: *common-build
  <<: *common-artifacts
  stage: AI Scan
  script:
    # creating aiproj file from variable or with default values
    - if [ ! "${USE_SERVER_SETTINGS}" == "true" ]; then if [ ! x"${PROJECT_SETTINGS}" = x ]; then echo ${PROJECT_SETTINGS} > "${PROJECT_NAME}.aiproj"; else set-settings --projectname "${PROJECT_NAME}" --language ${PROJECT_LANGUAGE}; fi; fi;
    # adding reports and policy parameters to the plugin
    - if [ ! x"${REPORT_JSON}" = x ]; then echo ${REPORT_JSON} > ai-reports.json && REPORT="--report-json=ai-reports.json"; fi;
    - if [ ! x"${POLICY_JSON}" = x ]; then echo ${POLICY_JSON} > ai-policy.json && POLICY="--policy-json=ai-policy.json"; fi;
    # check if the server is available
    - ptai-plugin check-server
    # run the scan in ui-ast or in json-ast mode
    - if [ "${USE_SERVER_SETTINGS}" == "true" ]; then ptai-plugin ui-ast --project="${PROJECT_NAME}" --input=./ --output=.ai_report ${REPORT} ${CUSTOM_PLUGIN_PARAMS}; else ptai-plugin json-ast --settings-json="${PROJECT_NAME}.aiproj" --input=./ --output=.ai_report ${REPORT} ${POLICY} ${CUSTOM_PLUGIN_PARAMS}; fi;
    - *push-AI-report-status-success-to-upstream

# --- Security Gates Stage ------------------------------------------

# This job processes the results of the AI-scanning and makes a verdict on them. See the documentation for more info
Check Security Gate:
  <<: *common-build
  stage: Security Gates
  before_script:
    - echo "${CODEQUALITY_SETTINGS}" > ./codequality.settings.yml
  script:
    - *codequality
    - *push-Security-Gates-status-to-upstream
  rules:
    - if: $CODEQUALITY_SETTINGS != ""
    - when: on_success
  needs:
    - job: AI-scanning
      artifacts: true
  artifacts:
    expire_in: 31 day
    paths:
      - codequality.json
    reports:
      dotenv: .env
      codequality: codequality.json

# Fake job for demonstration
#Send failed status to monitoring:
#  <<: *common-build
#  <<: *on-failure
#  stage: Security Gates
#  script:
#    - exit 0


# --- Notification Stage --------------------------------------------

# Fake job for demonstration
#Notify by email and chats (Success):
#  <<: *common-build
#  <<: *on-success
#  stage: Notifications
#  script:
#    - exit 0

# Fake job for demonstration
#Notify by email and chats (Failure):
#  <<: *common-build
#  <<: *on-failure
#  stage: Notifications
#  script:
#    - exit 0
